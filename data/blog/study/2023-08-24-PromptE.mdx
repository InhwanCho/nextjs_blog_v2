---
title: Prompt Engineering


tags:
- PROMPT
- LLM
- NLP

date: 2023-08-24
lastmod: 2023-08-24
 
---



## Prompt 란 ?

    - 과거에는 컴퓨터에 사람의 언어를 입력하면 컴퓨터가 인식을 제대로 할 수 없었기 때문에 
      [ls, cd, pwd]같은 명령어들이 프롬프트이며,

      현재는 ChatGPT같은 모델에 입력하는 명령어 
      'ex- ChatGPT가 무엇인지 설명해줘' 같은 인간의 언어도 프롬프트이다.


## Prompt Engineering 이란 ?

답변을 위한 `적절한 컨텍스트` , `원하는 결과와 포맷(json, markdown, ...)의 출력을 위한 프롬프트 작성`을 하는 엔지니어링입니다.

즉, `어쩌다 한 번 결과를 내는 것이 아닌, 항상 일관성 있게 의도한 결과를 내도록 프롬프트를 작성하는 것`입니다.

    - ChatGPT같은 생성 모델에서 더 나은 결과 값을 얻기위해 프롬프트(입력문)를 최적화하는 직업
    - ex- ChatGPT가 무엇인지 2줄로 요약을 해줘. 문장 시작은 1,2로 시작해줘

    '수능 예상 문제 만들어줘'가 아닌 
    '수능 수리영역에 피타고라스의 정의가 들어가는 예상 문제 3개 만들어줘'처럼 작성하는 것입니다.

---

## 프롬프트 엔지니어링 방법

대략적인 엔지니어링 설계 방법은 다음의 방법을 활용하면 됩니다.

1. 프롬프트 예상 결과 설정
2. 프롬프트 평가 설계
3. 그라운딩 설계 및 평가
4. 프롬프트 디자인
5. 모니터링 및 개선



---

### 프롬프트 구성 요소 

- Role(역할) 설정
  
      페르소나를 설정(배경 지식을 가지고 답하므로 정확도 향상)

      예시 1) 
      당신은 바리스타입니다. 나는 산미를 좋아하는데 원두 추천해줘.

      예시 2) 
      당신은 스포츠기자입니다. 
      주요 해외 축구 기사 이벤트를 보고서를 markdown 형식으로 작성해줘

- Policy(rule)

      예시 1)
      가짜 정보를 사용하여 뉴스를 작성해주세요

      예시 2)
      공손한 말투로 위의 답변을 200자 내로 변경해주세요

- Audience(constraint)

      특정 그룹을 설정

      예시 1)
      기타 입문자를 위한 곡을 추천해줘

      예시 2)
      숙련된 클라이머를 위한 손가락 트레이닝 루틴을 작성해줘

- Knowledge(info)

      참고할 정보 출처를 지정
      
      예시 1)
      위키피디아의 내용에 따라 세종대왕에 대해 설명을 요약해줘

- Task

      수행해야 할 특정 작업 및 목표를 지정

      예시 1)
      ChatGPT가 무엇인지 3줄로 작성해줘

      예시 2)
      프롬프트를 개선하기 위한 제안을 제시해주세요

- Format
    
      예시 1)
      markdown 형식으로 결과를 출력해줘

- Examples(few-shot learning)
  
      예시 1)
      질문 : 기억, 학습
      답변 : 이것은 기억력 향상에 도움을 주는 학습 방법이다.

      질문 : 휴대폰, 기술
      답변 : 휴대폰은 현대 기술으로 만들어진 무선 이어폰이다.

      질문 : 볼펜, 코끼리
      답변 : 


### 위의 기술들을 기반으로 프롬프트를 작성하면 다음과 같습니다. 

```text
---
당신은 유머러스한 영어 선생님입니다.
다음의 정보를 참고하여 초등학생에게 이순신 장군에 대해 설명해주세요.
위키피디아의 설명을 참고해 답변해주세요.
---
다음의 규칙에 따라 답변을 작성해주세요.
- 교육적인 톤으로 작성
- 쉬운 영어로 작성
- 500자 내의 길이로 작성
- 대화 형식으로 작성

결과 예시 :
Q : 이순신 장군이 누구야?
A : 이순신 장군은 16세기 말 조선의 명장이자 구국영웅인 충무공 ...
Q :
```

---

## 프롬프트 엔지니어링의 대표적 기술

    1. Zero-shot/ One-shot/ Few-shot learning(examples)
    2. Chain of Thought(CoT)
    3. Self-Consistency
    4. Selection-Inference
    5. Least-to-Most
    6. React
    7. Self Evaluation


1. `few-shot learning`은 예시를 주고 예상 답변을 기대하는 것입니다.

- 예시가 없을 경우 zero-shot
- 예시가 1개면 one-shot, 여러개면 few-shot learning이라 합니다.

2. `Chain of Thouhgt(CoT)`은 

- 이유에 대해 설명하도록 만들어 답을 더 정확하게 만드는 기술
- 중간 추론 단계를 거치도록 하여 복잡한 작업에 정확도를 향상하는 방법

LLM은 산술연산에 약한 편이라서 중간 추론 단계를 작성해줘야 정확한 답변을 낼 확률이 높아집니다.

`Zero-Shot Chain of Thought`은 `천천히 생각해` 라고 지시를 하면 보다 나은 답변을 내주는 기술입니다.

- ChatGPT의 경우 `zero-shot CoT`가 default로 지정되 있습니다.

3. `Self-Consistency`은 같은 질문(프롬프트)로 여러번 반복 실행하고, 그 중 좋은 결과를 선책

4. `Selection-Inference`은 여러 추론 단계를 연결하기 위한 방법입니다.

- context에서 질문에 답할 수 있는 정보를 선택 -> 그 답변을 기반으로 선택하게 유도
- 이 방법은 추론 단계를 추적 가능하여 디버깅에 유용합니다.


5. `Least-to-Most` 최종 답변이 나올때까지 여러번 질문을 변경하는 방법입니다.

- Task를 분할하여 작은 문제를 순차적으로 풀어해치는 방법.
- CoT + Selection-inference

6. `ReAct` 실행 계획을 유도하고 추적하여 작업별 실행할 액션을 선택하고 실행하는 방법

- 외부 API/검색엔진을 통해 정보를 사용하거나 계산기나 이미지 생성 등의 도구를 사용할 수 있음.
- 실제로 사용할 때는 각 단계별로 끊어서 결과를 제어할 필요가 있음.(+ 토큰 제어 유의)

      예시)
      생각, 행동, 관찰 단계를 번갈아 가며 질문 응답 작업을 해결합니다.
      생각은 현재 상황에 대해 추론 할 수 있고, 행동은 세가지 유형이 있습니다.

      1) Serch[entity],이는 위키 백과에서 정확한 entity를 검색하고 존재하는 경우 첫 번째 문단을 반환합니다. 
      존재하지 않는 경우, 검색할 수 있는 유사한 entity를 반환합니다.

      2) Lookup[keyword], 이는 현재 문단에서 키워드를 포함하는 다음 문장을 반환합니다.

      3) Finish[keyword], 이는 답을 반환하고 작업을 종료합니다.

      질문 : 대한민국의 인천 인구는 몇 명인가요?
      
      ---

      GPT :
      생각 1 : 대한민국의 인천 인구를 찾아야 합니다.
      행동 1 : Search[대한민국 인천 인구]
      관찰 1 : 인천의 인구는 ... 명 입니다.
      생각 2 : 인천의 인구는 ... 명 입니다.
      행동 2: finish[약 ...명]

7. `Self Evaluation` AI가 스스로 결과를 평가하고 향상시키는 방법



---

## 프롬프트 보안



    - 구분자를 사용하여 프롬프트에 입력
    - 사용자의 입력값 이전과 이후를 나눠서 구성
    - 사용자의 입력 이전의 프롬프트 내용에 답변하지 말라고 지시

예시) 

```text
''' 구분자 안의 내용을 번역하세요.

번역할 내용 :
'''
{사용자가 입력한, 번역을 요청한 내용}
'''
```

## Token

한글에 대한 토큰 사용이 비효율적이므로 (영어와 언어 체계가 다름) 보통 바이트 단위로 토큰화함.

-> 이를 해결하기 위해 프롬프트의 `입/출력을 영어로 작성`하거나 `입/출력을 번역하여 사용`

### Context Window

CNN의 stride와 유사한 개념입니다.  
문맥을 판단하거나 다음 단어를 `예측하기 위해 참고할 토큰의 범위`입니다.

### LLM 생성의 주요 하이퍼파라미터

- Temperature

      값이 높을 수록 다양한 출력을 만들어줍니다.(무작위적 & 높은 환각)
      낮으면 일관적인 답변을 출력합니다.

- Top P, Top k

      Top P는 확률이 상위 'P %'인 토큰을 선택
      Top K는 확률이 상위 K개의 토큰을 선택

      매우 높은 Temperature를 설정 시 너무 무작위의 답변이 나오는 것을 방지

- Maximum length

      최대 토큰 수 설정

      입력 가능한 토큰 수 = 모델의 최대 토큰 수 - Maximum length


- Frequency Penalty

      동일한 표현을 주는 출력을 할 시 패널티를 줘서 반복하지 않게 함
- Presence Penalty

      Frequency Penalty와 반대되는 옵션

- Injection Start

      답변의 시작 단어를 지정해줍니다.


## 참고 자료

[Selection-Inference 논문](https://arxiv.org/abs/2205.09712 'paper')

[OpenAI Playground](https://platform.openai.com/playground 'openai playground')